pixels = matrix(X[,i], nrow=28, byrow=TRUE)
image(t(apply(pixels, 2, rev)) , col=gray((255:0)/255),
xlab="", ylab="", main=paste("Label for this image:", y[i]))
i = 1000 # 1000レコード目
pixels = matrix(X[,i], nrow=28, byrow=TRUE)
image(t(apply(pixels, 2, rev)) , col=gray((255:0)/255),
xlab="", ylab="", main=paste("Label for this image:", y[i]))
# Chunk 15
# testとtrainに分割
# ID列を追加
df = mnist %>% rownames_to_column("ID")
# 80%を学習用データに
train <- df %>% sample_frac(size = 0.8)
# 学習用データに使っていないIDの行をテスト用データに
test <- anti_join(df, train, by = "ID")
# ID列は予測に使わないため削除しておく
train <- train %>% select(-ID)
test <- test %>% select(-ID)
# Chunk 16
# 教師データのラベル
table(train[, 1])
# Chunk 17
# ライブラリの用意
if(!require(h2o)) {install.packages("h2o")}
library(h2o)
# 初期化
h2o.init()
# データをh2o用のデータ型に変換
train <- as.h2o(train)
test <- as.h2o(test)
# 1列目（目的変数）をfactor型に変換
train[,1] = h2o::as.factor(train[,1])
test[,1] = h2o::as.factor(test[,1])
# Chunk 18
# trainデータを学習用のものと検証用のものに分ける
splits <- h2o.splitFrame(train, ratios = 0.8, seed = 0)
# Chunk 19
# 学習
mnist_dl = h2o.deeplearning(
x = 2:ncol(train), # 特徴量の列番号を指定
y = 1,             # 目的変数の列番号を指定
training_frame = splits[[1]],   # 訓練データを指定
validation_frame = splits[[2]], # 検証データを指定（学習には使わず、精度を測るためだけに使う）
activation = c("RectifierWithDropout"), # 活性化関数を指定
hidden = c(64, 32, 16), # 中間層（隠れ層）のサイズ
epochs = 20,       # エポック数。学習データ何回分の学習を反復させて重みを更新していくか。
hidden_dropout_ratios = c(0.5, 0.5, 0.5), # 各中間層においてdropoutするユニットの割合
sparse = TRUE,     # 0が多いデータ（スパースデータ）の取り扱い方を変え、メモリ使用量を抑える。
seed = 0
)
# Chunk 20
mnist_dl
# エポック数ごとの訓練データに対する予測誤差の推移
plot(mnist_dl)
mnist_dl
install.packages("DiagrammeR")
install.packages("DiagrammeR")
library(DiagrammeR)
install.packages("DiagrammeR")
library(glue)
install.packages("glue")
install.packages("DiagrammeR")
library(glue)
install.packages(c("backports", "bayestestR", "BH", "blob", "broom", "car", "carData", "caret", "class", "cli", "conquer", "corrplot", "crayon", "crosstalk", "data.table", "datawizard", "DBI", "digest", "DT", "dtplyr", "estimatr", "fansi", "flextable", "forecast", "foreign", "fs", "future", "generics", "ggsignif", "glmnet", "glue", "googlesheets4", "haven", "hms", "htmltools", "htmlwidgets", "insight", "ipred", "isoband", "jsonlite", "knitr", "later", "lattice", "lava", "lifecycle", "lmtest", "lubridate", "maptools", "MASS", "Matrix", "matrixStats", "mgcv", "mime", "modelsummary", "nlme", "nloptr", "nnet", "officer", "openssl", "openxlsx", "padr", "parallelly", "parameters", "performance", "pillar", "plotly", "pROC", "psych", "Quandl", "R6", "Rblpapi", "Rcpp", "RcppArmadillo", "readr", "recipes", "remotes", "repr", "reprex", "rio", "rJava", "rlang", "rmarkdown", "rsample", "Rttf2pt1", "rvest", "sp", "spatial", "stringi", "survival", "systemfonts", "tibble", "tidyr", "timetk", "tinytex", "tseries", "TTR", "utf8", "uuid", "withr", "xfun", "xml2"))
pacman::p_load(DiagrammeR)
# 事前準備 --------------------
# パッケージの読み込み
pacman(tidyverse, estimatr, plm, stargazer,texreg)
# 事前準備 --------------------
# パッケージの読み込み
library(pacman)
pacman(tidyverse, estimatr, plm, stargazer,texreg)
pacman::p_load(tidyverse, estimatr, plm, stargazer,texreg)
pacman::p_load(tidyverse, estimatr, plm, stargazer,texreg)
# Chunk 1
knitr::opts_chunk$set(fig.align = 'center', message = F, warning = F,
fig.height=3, fig.width=4)
# Chunk 3
# パッケージの読み込み
library(AER)
# データの読み込み
data("CPS1985")
# Chunk 4
head(CPS1985)
pacman::p_load(readxl, tidyverse, skimr, AER)
pacman::p_load(readxl, tidyverse, skimr, AER)
# データの読み込み
data("CPS1985")
head(CPS1985)
summary(CPS1985)
skimr::skim(CPS1985)
# データの読み込み
data("CPS1985")
head(CPS1985)
#textでの表示
stargazer(CPS1985, type = "text")
# Chunk 1
knitr::opts_chunk$set(fig.align = 'center', message = F, warning = F,
fig.height=3, fig.width=4)
# Chunk 2
pacman::p_load(readxl, tidyverse, skimr, AER, stargazer)
# Chunk 3
# データの読み込み
data("CPS1985")
head(CPS1985)
# Chunk 4
summary(CPS1985)
skimr::skim(CPS1985)
#textでの表示
stargazer(CPS1985, type = "text")
#htmlで表示し、summary_CPS1985.htmlという名前での保存
stargazer(CPS1985, type = "html", out = "summary_CPS1985.html")
# Chunk 1
knitr::opts_chunk$set(fig.align = 'center', message = F, warning = F,
fig.height=3, fig.width=4)
# Chunk 2
pacman::p_load(readxl, tidyverse, skimr, AER, stargazer, gridExtra, estimatr)
# Chunk 3
# データの読み込み
data("CPS1985")
head(CPS1985)
# Chunk 4
summary(CPS1985)
skimr::skim(CPS1985)
# Chunk 5
#textでの表示
stargazer(CPS1985, type = "text")
# Chunk 6
#htmlで表示し、summary_CPS1985.htmlという名前での保存
stargazer(CPS1985, type = "html", out = "summary_CPS1985.html")
# Chunk 7
# Regression
reg <- lm(formula = wage ~ education,
data = CPS1985) # 教育年数が賃金を決めるモデル
reg
# Chunk 8
summary(reg)
# Chunk 9
stargazer(reg, type = "text")
# Chunk 11
g1 <- ggplot(CPS1985, aes(x = wage))+
geom_histogram(bins = 10)
g2 <- ggplot(CPS1985, aes(x = log(wage)))+
geom_histogram(bins = 10)
grid.arrange(g1, g2) #gridextraパッケージによるグラフの結合。他にもpatchworkパッケージなどがある。
# Chunk 12
# g1 <- ggplot(CPS1985, aes(x = education, y = wage))+
#   geom_point(alpha = 0.5)+
#   geom_smooth(method = "loess", se = F)
# g2 <- ggplot(CPS1985, aes(x = education, y = log(wage)))+
#   geom_point(alpha = 0.5)+
#   geom_smooth(method = "loess", se = F)
# Chunk 13
reg_logwage <- lm(formula = log(wage) ~ education,
data = CPS1985)
# Chunk 14
stargazer(reg, reg_logwage, type = "text")
# Chunk 15
reg_multiple <- lm(formula = log(wage) ~ education + experience, data = CPS1985)
# Chunk 16
stargazer(reg_logwage, reg_multiple, type = "text")
# mutate関数で新しい変数を追加したデータをdfオブジェクトに代入
df = CPS1985 %>% dplyr::mutate(experience2 = experience^2)
reg_mincer <- lm(formula = log(wage) ~ education + experience + experience2, data = df)
reg_mincer <- lm(formula = log(wage) ~
education + experience + experience2,
data = df)
stargazer(reg_logwage, reg_multiple, reg_mincer,
type = "html",
out = "04reg_table.html")
# パッケージの読み込み
library("estimatr")
# ロバスト標準誤差を用いたOLS推定
reg_logwage_r <-
lm_robust(formula = log(wage) ~ education,
data = CPS1985, se_type = "HC1")
reg_multiple_r <-
lm_robust(formula = log(wage) ~ education + experience,
data = CPS1985, se_type = "HC1")
reg_mincer_r <-
lm_robust(formula = log(wage) ~ education + experience + experience2,
data = df, se_type = "HC1")
summary(reg_logwage_r)
summary(reg_multiple_r)
summary(reg_mincer_r)
# Chunk 1
knitr::opts_chunk$set(fig.align = 'center', message = F, warning = F,
fig.height=3, fig.width=4)
# Chunk 2
pacman::p_load(readxl, tidyverse, skimr, AER, stargazer, gridExtra, estimatr, texreg)
# Chunk 4
# データの読み込み
data("CPS1985")
head(CPS1985)
# Chunk 5
summary(CPS1985)
skimr::skim(CPS1985)
# Chunk 6
#textでの表示
stargazer(CPS1985, type = "text")
# Chunk 7
#htmlで表示し、summary_CPS1985.htmlという名前での保存
stargazer(CPS1985, type = "html", out = "summary_CPS1985.html")
# Chunk 8
# Regression
reg <- lm(formula = wage ~ education,
data = CPS1985) # 教育年数が賃金を決めるモデル
reg
# Chunk 9
summary(reg)
# Chunk 10
stargazer(reg, type = "text")
# Chunk 12
g1 <- ggplot(CPS1985, aes(x = wage))+
geom_histogram(bins = 10)
g2 <- ggplot(CPS1985, aes(x = log(wage)))+
geom_histogram(bins = 10)
grid.arrange(g1, g2) #gridextraパッケージによるグラフの結合。他にもpatchworkパッケージなどがある。
# Chunk 13
# g1 <- ggplot(CPS1985, aes(x = education, y = wage))+
#   geom_point(alpha = 0.5)+
#   geom_smooth(method = "loess", se = F)
# g2 <- ggplot(CPS1985, aes(x = education, y = log(wage)))+
#   geom_point(alpha = 0.5)+
#   geom_smooth(method = "loess", se = F)
# Chunk 14
reg_logwage <- lm(formula = log(wage) ~ education,
data = CPS1985)
# Chunk 15
stargazer(reg, reg_logwage, type = "text")
# Chunk 16
reg_multiple <- lm(formula = log(wage) ~ education + experience, data = CPS1985)
# Chunk 17
stargazer(reg_logwage, reg_multiple, type = "text")
# Chunk 18
# mutate関数で新しい変数を追加したデータをdfオブジェクトに代入
df = CPS1985 %>% dplyr::mutate(experience2 = experience^2)
# Chunk 19
reg_mincer <- lm(formula = log(wage) ~
education + experience + experience2,
data = df)
# Chunk 20
stargazer(reg_logwage, reg_multiple, reg_mincer,
type = "text")
# Chunk 21
stargazer(reg_logwage, reg_multiple, reg_mincer,
type = "html",
out = "04reg_table.html")
# Chunk 23
# パッケージの読み込み
library("estimatr")
# ロバスト標準誤差を用いたOLS推定
reg_logwage_r <-
lm_robust(formula = log(wage) ~ education,
data = CPS1985, se_type = "HC1")
reg_multiple_r <-
lm_robust(formula = log(wage) ~ education + experience,
data = CPS1985, se_type = "HC1")
reg_mincer_r <-
lm_robust(formula = log(wage) ~ education + experience + experience2,
data = df, se_type = "HC1")
# Chunk 24
summary(reg_logwage_r)
summary(reg_multiple_r)
summary(reg_mincer_r)
#結果表の出力
screenreg(list(reg_logwage_r, reg_multiple_r, reg_mincer_r),
include.ci = FALSE, digits = 3)
# Chunk 1
knitr::opts_chunk$set(fig.align = 'center', message = F, warning = F)
# Chunk 2
pacman::p_load(tidyverse, plotly, DiagrammeR)
# Chunk 3
grViz("digraph dot{
graph[rankdir = LR]
node[shape = circle, fontname = 'Yu Gothic']
edge[fontname = 'Yu Gothic', fontsize = 10]
能力A -> 所得Y [label='10']
能力A -> 学歴X [label='A≧80からランダム抽出']
学歴X -> 所得Y [label='500']
{rank = same; 能力A; 学歴X}
}")
# grViz("digraph dot{
# graph[rankdir = LR]
#
# node[shape = circle, fontname = 'Yu Gothic']
#
# edge[]
# 能力A -> {所得Y; 学歴X; テストの点}
# テストの点 -> 学歴X -> 所得Y
#       }")
# 乱数の種を固定　=>　毎回同じように乱数を発生させるようにする。0を他の数値に変えると異なる乱数となる。
set.seed(0)
# n:サンプルサイズ
n <- 10000
# 能力は0から100まで均等に分布。#runifは一様分布を発生させる関数。標本規模n、最小値0、最大値100
ability <- runif(n, min = 0, max = 100)
df <- tibble(ID = 1:n, ability)
university_df <- df %>% filter(ability >= 80) %>%
sample_frac(0.5) # 大卒の人
university_df["university"] = 1
# Chunk 1
knitr::opts_chunk$set(fig.align = 'center', message = F, warning = F)
# Chunk 2
pacman::p_load(tidyverse, plotly, DiagrammeR)
# Chunk 3
grViz("digraph dot{
graph[rankdir = LR]
node[shape = circle, fontname = 'Yu Gothic']
edge[fontname = 'Yu Gothic', fontsize = 10]
能力A -> 所得Y [label='10']
能力A -> 学歴X [label='A≧80からランダム抽出']
学歴X -> 所得Y [label='500']
{rank = same; 能力A; 学歴X}
}")
# grViz("digraph dot{
# graph[rankdir = LR]
#
# node[shape = circle, fontname = 'Yu Gothic']
#
# edge[]
# 能力A -> {所得Y; 学歴X; テストの点}
# テストの点 -> 学歴X -> 所得Y
#       }")
# 乱数の種を固定　=>　毎回同じように乱数を発生させるようにする。0を他の数値に変えると異なる乱数となる。
set.seed(0)
# n:サンプルサイズ
n <- 10000
# 能力は0から100まで均等に分布。#runifは一様分布を発生させる関数。標本規模n、最小値0、最大値100
ability <- runif(n, min = 0, max = 100)
df <- tibble(ID = 1:n, ability)
university_df <- df %>% filter(ability >= 80) %>%
sample_frac(0.5) # 大卒の人
university_df["university"] = 1
View(university_df)
university_df <- university_df %>% dplyr::mutate(university == 1)
university_df <- university_df %>%
dplyr::mutate(university = 1)
# n:サンプルサイズ
n <- 10000
# 能力は0から100まで均等に分布。#runifは一様分布を発生させる関数。標本規模n、最小値0、最大値100
ability <- runif(n, min = 0, max = 100)
df <- tibble(ID = 1:n, ability)
university_df <- df %>% filter(ability >= 80) %>%
sample_frac(0.5) # 大卒の人
university_df <- university_df %>%
dplyr::mutate(university = 1)
# dfからdplyr::anti_join()を用いて"university_df"とマッチしなかった人を抽出する。
no_university_df <- anti_join(df, university_df,
by = c("ID","ability")) # 大卒ではない人
View(no_university_df)
# no_university_dfのデータフレームに、universityという変数を作成し、すべて0とする。
no_university_df <- no_university_df %>%
dplyr::mutate(university = 0)
# university_dfとno_university_dfを、dplyr::bind_rowsを用いて結合してあたらしいdfとし、ID順で並べる
df <- bind_rows(university_df, no_university_df) %>%  # 両者を結合
arrange(ID) # ID順に並べる
df <- df %>% mutate(income = 200 + 10*ability + 500*university + rnorm(n, mean = 0, sd = 50)) # 誤差項は平均=0、SD=50
# 最初の6行
head(df)
## 大卒か否かのラベルをデータフレームに加える
df <- df %>% mutate(edu_label =
case_when(university == 1 ~ "Grad.",
university == 0 ~ "Not grad."))
## 散布図を描く with 大卒ラベル
ggplot(df, aes(x = ability, y = income, color = edu_label)) +
geom_point(alpha = 0.5)+
labs(title = "Ability and Income")
# 塗り分けプロット
# plot
## 散布図と回帰直線を描く with 大卒ラベル
ggplot(df, aes(x = ability, y = income, color = edu_label, group = edu_label)) + # groupごと
geom_point(alpha = 0.5)+
geom_smooth(method = "lm", color = "black") +  # 回帰直線
labs(title = "Ability and Income")
ols_S <- lm(formula = income ~ university, data = df)
stargazer(ols_S, type = "text")
# Chunk 1
knitr::opts_chunk$set(fig.align = 'center', message = F, warning = F)
# Chunk 2
pacman::p_load(tidyverse,
stargazer,
Hmisc,
AER,
estimatr,
texreg,
ivpack,
DiagrammeR)
# Chunk 3
#install.packages("Diagrammes")
grViz("digraph dot{
graph[rankdir = LR]
node[shape = circle, fontname = 'Yu Gothic']
edge[fontname = 'Yu Gothic', fontsize = 10]
能力A -> 所得Y [label='10']
能力A -> 学歴X [label='A≧80からランダム抽出']
学歴X -> 所得Y [label='500']
{rank = same; 能力A; 学歴X}
}")
# Chunk 4
#install.packages("Diagrammes")
grViz("digraph dot{
graph[rankdir = LR]
node[shape = circle, fontname = 'Yu Gothic']
edge[fontname = 'Yu Gothic', fontsize = 10]
能力A -> 所得Y [label='10']
能力A -> 学歴X [label='A≧80からランダム抽出']
学歴X -> 所得Y [label='500']
学費免除Z -> 学歴X [label='50％の確率で大学を卒業']
{rank = same; 能力A; 学歴X}
}")
# Chunk 5
# 事前準備 --------------------
# パッケージの読み込み
library(tidyverse)
# 乱数の種を固定　=>　毎回同じように乱数を発生させるようにする。0を他の数値に変えると異なる乱数となる。
set.seed(0)
# データの生成 ----------------
# n:サンプルサイズ
n <- 10000
# 能力は0から100まで均等に分布。#runifは一様分布を発生させる関数。標本規模n、最小値0、最大値100
ability <- runif(n, min = 0, max = 100)
# IDとabilityをデータフレームに格納する。
# 以下の"tibble()"はtidyverseにおけるデータフレームを作成する関数。
# 代わりに"data.frame()"を用いても構わない。
df <- tibble(ID = 1:n, ability)
# 大卒ダミーの作成
# 能力が 80 以上の約 2000人の中から約 1000人をランダムに選ばれて、大卒にする。
# dfからdplyr::filter()で抽出し、sample_fram()でさらに半分をランダムに抽出する。
university_df <- df %>% filter(ability >= 80) %>% sample_frac(0.5) # 大卒の人
# university_df のデータフレームに、universityという変数を作成し、すべて1とする。
university_df <- university_df %>%
dplyr::mutate(university = 1)
#あるいは university_df["university"] = 1
# dfからdplyr::anti_join()を用いて"university_df"とマッチしなかった人を抽出する。
no_university_df <- df %>%
dplyr::anti_join(university_df,
by = c("ID","ability")) # 大卒ではない人
# no_university_dfのデータフレームに、universityという変数を作成し、すべて0とする。
no_university_df["university"] = 0
# university_dfとno_university_dfを、dplyr::bind_rowsを用いて結合してあたらしいdfとし、ID順で並べる
df_temp1 <- bind_rows(university_df, no_university_df) %>% # 両者を結合
arrange(ID) # ID順にする
# ここまで前回と同じ ------------
# ここから追加部分 --------------
# 条件３：学費免除制度とそれによる卒業
# 前回はsample_frac()を用いてランダムに大卒サンプルを抽出し、また結合するという方法を用いた。
# 今回は二項分布の乱数を発生させるrbinom()を用いて、
# 元のデータフレームに学費免除ダミー変数を追加したり、大卒ダミー変数を修正したりする。
# df_tempの個体は、能力に関係なく、30%の確率で学費免除（exemption = 1）となる
# rbinom(n, m, p): 成功確率pの試行をm回試みたときの成功回数の分布をnを生成
df_temp2 <- df_temp1 %>%
dplyr::mutate(exemption = rbinom(n, 1, 0.3))
# 学費免除（exemption=1）のときには、50%の確率で卒業できる（university=1）
# ただし、能力が80以上のときには学費免除の有無に関わりなく卒業できるものとする。
# mutate()の中でcase_when()を使う
# case_when()の場合分けでの数字生成がnumericで行われるように、as.numeric()の中でrbinomを使って0,1の乱数を生成
df <- df_temp2 %>%
mutate(university = case_when(exemption == 1 ~ as.numeric(rbinom(n, 1, 0.5)), # exemption=1なら50%の確率で1
university == 1 ~ 1, #すでにuniversity=1なら1
TRUE ~ 0)) # それ以外は0
# 所得の生成
df <- df %>%
dplyr::mutate(income = 200 + 10*ability + 500*university + rnorm(n, mean = 0, sd = 50)) # 誤差項は平均=0、SD=50
# 伝統的なやり方はこちら→df["income"] = 200 + 10*df["ability"] + 500*df["university"] + rnorm(n, mean = 0, sd = 50)  # 誤差項は平均=0、SD=50
# 最初の6行
head(df)
# Chunk 6
library()
describe(df)
# Chunk 7
# 塗り分けプロット
# plot
## 大卒か否かのラベルをデータフレームに加える
df <- df %>% mutate(edu_label =
case_when(university == 1 ~ "Grad.", university == 0 ~ "Not grad."))
## 散布図を描く with 大卒ラベル
ggplot(df, aes(x = ability, y = income, color = edu_label)) +
geom_point(alpha = 0.5)+
labs(title = "Ability and Income")
# Chunk 8
reg_biased1 = lm(income ~ university, data = df)
reg_biased2 = lm(income ~ university + exemption, data = df)
stargazer(reg_biased1, reg_biased2, type = "text")
# Chunk 9
first_stage = lm(university ~ exemption, data = df)
stargazer(first_stage, type = "text")
# Chunk 10
reduced_form = lm(income ~ exemption, data = df)
stargazer(reduced_form, type = "text")
# Chunk 11
reduced_form$coefficients[2] / first_stage$coefficients[2]
iv_reg = AER::ivreg(formula = income ~ university | exemption, # 被説明変数 ~ 説明変数 | 操作変数　と指定
data = df)
stargazer(iv_reg, type = "text")
iv_reg = AER::ivreg(formula = income ~ university | exemption, # 被説明変数 ~ 説明変数 | 操作変数　と指定
data = df)
stargazer(iv_reg)
screenreg(list(iv_reg))
screenreg(list(iv_reg),
include.ci = FALSE,
digits = 3))
screenreg(list(iv_reg),
include.ci = FALSE,
digits = 3)
summary(iv_reg)
texreg::screenreg(list(iv_reg),
include.ci = FALSE,
digits = 3)
texreg::htmlreg(list(iv_reg, iv_reg_robust2),
include.ci = FALSE,
digits = 3)
