---
title: "Rで学ぶ計量経済学と機械学習 7<br> <br> 計量経済学３：回帰不連続デザイン（+モンテカルロ・シミュレーション入門）"
author: "安藤道人（立教大学）　三田匡能 (株式会社 GA technologies)"
date: "`r Sys.Date()`"
output:
 html_document:
    css : R_style.css
    self_contained: true   # 画像などの埋め込み 
    #theme: cosmo
    highlight: haddock     # Rスクリプトのハイライト形式
    #code_folding: 'hide'  # Rコードの折りたたみ表示を設定
    toc: true
    toc_depth: 2           # 見出しの表示とその深さを指定
    toc_float: true        # 見出しを横に表示し続ける
    number_sections: true # 見出しごとに番号を振る
    # df_print: paged        # head()の出力をnotebook的なものに（tibbleと相性良）
    latex_engine: xelatex  # zxjatypeパッケージを使用するために変更
    fig_height: 4          # 画像サイズのデフォルトを設定
    fig_width: 6           # 画像サイズのデフォルトを設定
    dev: png
classoption: xelatex,ja=standard
editor_options: 
  chunk_output_type: console
---

```{r include = FALSE}
knitr::opts_chunk$set(fig.align = 'center', message = F, warning = F)
```

# 本講義の目的

- 回帰モデルを用いて不連続回帰デザインによる推定を行う方法を学ぶ。
- ループの活用やモンテカルロ・シミュレーションの基礎を学ぶ。

# パッケージの読み込み

今回の分析で使うパッケージを読み込む。ただし、{DiagrammeR}は因果ダイアグラムを書くために使うものであり、講義中には使わない。
```{r}
pacman::p_load(tidyverse, 
               stargazer, 
               Hmisc, 
               estimatr, 
               texreg, 
               DiagrammeR)
```

# ディレクトリの設定

作業ディレクトリを設定する。プロジェクト機能を活用できるのであれば、そちらを活用する。

```{r, eval = FALSE}
setwd(自分のディレクトリ) # ディレクトリの設定
getwd() # ディレクトリの確認
```

# データ

## データ生成過程
前回、前々回と同様、自分で生成したデータを用いて分析していく。

すなわち、個人の所得$Y$と学歴$X$・能力$A$との関係についての架空データを次のように生成する。

$$
Y = 200 + 10A + 500X+ \varepsilon
$$

- サンプルは1万人
- 切片は200万円
- 能力が1上がると所得は10上昇する
- 能力は0から100まで均等に分布する
- 大卒だと所得が500万円上昇する
- 能力を部分的に反映した学力テストの点数が 180点以上であれば大卒となる
- この最後の学力テスト点数が新しいデータ生成条件であり、これを回帰不連続デザインで利用する。


```{r, echo=F}
grViz("digraph dot{
graph[rankdir = LR]

node[shape = circle, fontname = 'Yu Gothic']

edge[fontname = 'Yu Gothic']
能力A -> 所得Y [label='10']
能力A -> テストの点 [label='能力を部分的に反映']
テストの点 -> 学歴X [label='180点以上かどうか']
学歴X -> 所得Y [label='500']

{rank = same; 能力A; テストの点; 学歴X}
}")
```


```{r}
# 事前準備 --------------------

# 乱数の種を固定
set.seed(0)

# データの生成 ----------------
n <- 10000
# 能力は0から100まで均等に分布
ability <- runif(n, min = 0, max = 100)

# IDとabilityをデータフレームに格納する
df <- tibble(ID = 1:n, ability)

# 大卒フラグ
## 条件：能力を部分的に反映した学力テストの点数が 180 点以上であれば大卒となる
## 10%くらいが該当するように恣意的に設定
## abilityとscoreの関係は非線形なものとする
## 今回はmutate()とcase_when()を使用して作成

#学力テストの点数 score
df <- df %>% mutate(score = 30*log10(ability) + 
                            rnorm(n, mean = 115, sd = 10))
#大卒ダミー university (score 180点以上=1)
df <- df %>% mutate(university = case_when(score >= 180 ~ 1, 
                                           TRUE ~ 0))
#所得 income
df <- df %>% mutate(income = 200 + 10*ability + 500*university +
                             rnorm(n, sd = 50))

##dplyrを使わないやり方だと、以下の通り。
#df["score"] = 30*log10(ability) + rnorm(n, mean = 115, sd = 10)
#df["university"] = 1*(df["score"] >= 180)
#df["income"] = 200 + 10*df["ability"] + 500*df["university"] + rnorm(n, sd = 50)

# 最初の6行
head(df)
```

## グラフと記述統計

こうして生成したデータの所得と能力・学歴・テストの点数の関係をプロットすると次のようになる。

```{r}
# 塗り分けプロット

## 大卒か否かのラベルをデータフレームに加える
df <- df %>% mutate(edu_label =
                      case_when(university == 1 ~ "Grad.", 
                                university == 0 ~ "Not grad."))

## 散布図を描く with 大卒ラベル
ggplot(df, aes(x = ability, 
               y = income, 
               color = edu_label)) + 
         geom_point(alpha = 0.5)+ 
         labs(title = "Ability and Income")
```

また、データの記述統計は以下のようになる。

```{r}
Hmisc::describe(df)
```

# モンテカルロ・シミュレーション入門

## (欠落変数を無視した)回帰分析

次に、欠落変数（能力$A$)を無視して、$Y$を$X$に回帰してみる。前回同様、単純な単回帰に加えて、学力テストの点数をコントロール変数に加えた重回帰分析も行ってみる。

回帰分析結果は以下のようになる。

```{r}
reg1 = lm(income ~ university, 
          data = df)
reg2 = lm(income ~ university + score, 
          data = df)

stargazer(reg1, reg2, 
          type = "text")
```

「大卒になることによる所得上昇の効果」は、単回帰分析(`reg1`)だと約`r round(reg1$coefficients[2], 0)`（万円）と過大推定される。

`score`を含めた重回帰分析(`reg2`)だとおよび約`r round(reg2$coefficients[2], 0)`（万円）となる。

## モンテカルロ・シミュレーションとは

`score`を含めた重回帰分析(`reg2`)における約`r round(reg2$coefficients[2], 0)`（万円）という係数推定値は、500（万円）に比較的近いが、これは、学力テストの点数(`score')をコント―ルすることによって欠落変数バイアスが完全に除去できた結果なのだろうか？

このことを、理論的にではなく、基本的なシミュレーションにより検証してみよう。

もし上記の重回帰モデル(`reg2`)におけるOLS推定量が正しいのであれば、上記の`r round(reg2$coefficients[2], 0)`（万円）と500（万円）の差は「たまたま」生じたにすぎないということになる。

したがって、同様のデータ生成と回帰分析を何百回・何千回と実施すれば、`university`の係数のOLS推定値は500(万円)を中心に正規分布するはずである。これを実際に施行してみるのが、モンテカルロ・シミュレーションである。

## モンテカルロ・シミュレーションの実行

下記では、上記のデータ生成と回帰分析(`reg2`)をループによって1000回繰り返し、その結果を保存する。

```{R results = "hide"}
#タネの設定
set.seed(0) 

# シミュレーション結果を入れる「箱」の作成
coef <- rep(NA,1000)

# 同じ回帰分析(上のreg2)を1000回繰りかえす。

for(i in 1:1000){ # forによるループ。1000回繰り返す

# データ生成
n <- 10000

ability <- runif(n, min = 0, max = 100) # 能力は0から100まで均等に分布

df <- tibble(ID = 1:n, ability) # IDとabilityをデータフレームに格納する

df <- df %>% mutate(score = 30*log10(ability) + 
                            rnorm(n, mean = 115, sd = 10))

df <- df %>% mutate(university = case_when(score >= 180 ~ 1, 
                                           TRUE ~ 0))

df <- df %>% mutate(income = 200 + 10*ability + 500*university + 
                             rnorm(n, sd = 50))

# 回帰
reg2 <- lm(income ~ university + score, 
           data = df)

# 回帰係数推定値の保存
coef[i] = reg2$coefficients[2] 
}
```

シミュレーション結果（`university`の係数推定値の平均、標準偏差、ヒストグラム）は以下のようになる。

```{R}
#平均、標準誤差
mean(coef)
sd(coef)

# ヒストグラム
hist(coef)
```

平均は`r round(mean(coef), 1)`、標準偏差は`r round(sd(coef), 1)`であり、上記の`reg2`の回帰係数値とその標準誤差と近い。

そして、`reg2`を1000回施行して得た`university`の係数推計値の平均が`r round(mean(coef), 1)`であり、500から十分離れていることより、`reg2`の回帰モデルの`university`のOLS推定量にもバイアスがあることも分かる。


# 回帰不連続デザイン

`ability`変数がない限り、通常の回帰分析では推定結果にバイアスが生じてしまう。そこで、「能力を部分的に反映した学力テストの点数が 180 点以上であれば大卒となる」という条件を利用した分析を考える。

まず冒頭のデータをもう一度生成させる。

```{r}
# データ生成
set.seed(0)

n <- 10000

ability <- runif(n, min = 0, max = 100)

df <- tibble(ID = 1:n, ability)

df <- df %>% mutate(score = 30*log10(ability) + 
                            rnorm(n, mean = 115, sd = 10))

df <- df %>% mutate(university = case_when(score >= 180 ~ 1, 
                                           TRUE ~ 0))

df <- df %>% mutate(income = 200 + 10*ability + 500*university + 
                             rnorm(n, sd = 50))
```

X軸を学力テストの点数(`score`)、Y軸を所得(`income`)として散布図を描くと、下記のようになる。

```{r}
# 塗り分けプロット

## 大卒か否かのラベルをデータフレームに加える
df <- df %>% mutate(edu_label =
                      case_when(university == 1 ~ "Grad.", 
                                university == 0 ~ "Not grad."))

## 散布図を描く with 大卒ラベル
ggplot(df, aes(x = score, 
               y = income, 
               color = edu_label)) + 
         geom_point(alpha = 0.5) + 
         labs(title = "Score and Income")
```

テストの点数(`score`)の閾値（180点）を境に、所得が全体的に上振れ（ジャンプ）している。これは、学力テストで180点を大卒とおなり、所得が上昇するからである。

**回帰不連続デザイン**(regression discontinuity design: RD design, RDD)はこうした閾値を伴うデータ生成過程(DGP)を利用する調査設計（デザイン）で，以下のようなロジックをもとに分析を行う。

- スコアが180点になる閾値で大卒になれるかどうかという「不連続な変化」を決めるというのは人為的な制度であり，その背景にある個々人の所得の決定要因（ここでは能力$A$のみだが、一般的にはあらゆる決定要因）は「連続的」に分布しているはず。
- したがって，この閾値において所得に明確なジャンプ（不連続性）がある理由は、この閾値で同じく不連続に変化している「大卒」という要因以外には考えられない

## RDデザインによる推定

RDデザインの推定は、より高度なRD推定方法を扱うパッケージが存在するが、`lm`関数を使った重回帰分析で推定できる。

基本的には閾値（ここでは`score=180`)での「ジャンプ」の大きさを推定すればよい。

もっとも簡単な方法は、線形回帰分析でこのジャンプを推定することである。まずは簡便に、`ggplot2`を使って、グラフを使ってこのジャンプを確認してみよう。


```{R}
## 散布図を描く with 大卒ラベル
ggplot(df, aes(x = score, 
               y = income, 
               color = edu_label, 
               group = edu_label)) + 
         geom_point(alpha = 0.5) + 
         labs(title = "Score and Income") +
         geom_smooth(method = lm, 
                     se = TRUE, 
                     color = "black") # group=edu_labelごとの回帰直線, SEあり
```


上図のようなRD分析を線形RD(linear RD)と呼び、以下のように推定できる。

```{r}
# 閾値=0となるように割当変数(score_gap)を作り直す
df <- df %>% mutate(score_gap = score - 180)

# 線形RD: X軸にscore_gapを用いることにより、y切片の変化すなわちuniversityダミーの係数を上図の「ジャンプ」の大きさと解釈できる。
linear_RD <- lm(income ~ university + score_gap + score_gap:university, 
                data = df) 
stargazer(linear_RD, 
          type = "text")
```

`university`の係数は閾値でのジャンプの大きさ、`score`の係数は閾値左側の回帰直線の傾き、`score:university`の係数は閾値左側と閾値右側の回帰直線の傾きの変化である。`university`の係数推定値は500に近い。

## 多項式RD

閾値でのジャンプの大きさを測りたいだけなのに、閾値の左右における`score`と`income`の関係を線形回帰モデルで捉えるのは適切ではないかもしれない。

ただし、loess曲線を用いて閾値の左右における`score`と`income`の関係をフレキシブルな曲線で捉えてみても、ジャンプの大きさはあまり変わらないように見える。

```{R}
## 散布図を描く with 大卒ラベル
ggplot(df, aes(x = score, 
               y = income, 
               color = edu_label, 
               group = edu_label)) + 
         geom_point(alpha = 0.5)+ 
         labs(title = "Score and Income") +
         geom_smooth(method = lm, 
                     se = TRUE, 
                     color = "black") + # group=edu_labelごとの回帰直線, SEあり
         geom_smooth(method = loess, 
                     se = TRUE, 
                     color = "black")   # group=edu_labelごとのloess曲線, SEあり
```

そこで、閾値の左右における`score`と`income`の関係を、それぞれ異なる二次、三次、四次曲線でとらえた多項式RDを推定してみる。

```{r}
# 二次多項式RD, I(score_gap^2)はscore_gap^2
secondpoly_RD <- lm(income ~  university + 
                              score_gap + 
                              I(score_gap^2) + 
                              score_gap:university + 
                              I(score_gap^2):university, 
                    data = df) 

# 三次多項式RD,  I(score_gap^3)はscore_gap^3
thirdpoly_RD <- lm(income ~  university + 
                             score_gap + 
                             I(score_gap^2) + 
                             I(score_gap^3) +
                             score_gap:university + 
                             I(score_gap^2):university + 
                             I(score_gap^3):university, 
                   data = df) 

# 四次多項式RD, I(score_gap^4)はscore_gap^4
fourthpoly_RD <- lm(income ~  university + 
                              score_gap + 
                              I(score_gap^2) + 
                              I(score_gap^3) + 
                              I(score_gap^4) +
                              score_gap:university + 
                              I(score_gap^2):university +
                              I(score_gap^3):university + 
                              I(score_gap^4):university , 
                    data = df) 


# 一次~四次多項式RD
stargazer(linear_RD, 
          secondpoly_RD, 
          thirdpoly_RD, 
          fourthpoly_RD, 
          type = "text", 
          digits = 1, 
          df = FALSE) # 幅を狭くするため、digits=1, df=FALSEとする
```

どの結果も、`university`の係数推定値は、だいたい500前後になる。ただし、多項式の次元を大きくしていくほど、標準誤差も大きくなる。

## 局所線形RD

もう一つの考え方として、閾値から遠ざかるほど、閾値でのジャンプの大きさを測るには不必要な情報となる。したがって、線形モデルでのRDを使いつつ、推定に用いるサンプルを閾値近傍の局所的（local)なものに限定すればよいのではないかと考える。

この考え方に従って、閾値前後のバンド幅(bandwidth)を設定し、そのバンド幅の内部のサンプルだけを使って線形RDを行う。

```{r}
# バンド幅=50
band30_df <- df %>% filter(-30 <= score_gap & score_gap < 30) 
band30_RD <- lm(income ~ university + score_gap + score_gap:university, 
                data = band30_df) 

# バンド幅=10
band10_df <- df %>% filter(-10 <= score_gap & score_gap < 10) 
band10_RD <- lm(income ~ university + score_gap + score_gap:university, 
                data = band10_df) 

# バンド幅=5
band5_df <- df %>% filter(-5 <= score_gap & score_gap < 5) 
band5_RD <- lm(income ~ university + score_gap + score_gap:university, 
               data = band5_df) 

# バンド幅=1
band1_df <- df %>% filter(-1 <= score_gap & score_gap < 1) 
band1_RD <- lm(income ~ university + score_gap + score_gap:university, 
               data = band1_df) 

stargazer(band30_RD, 
          band10_RD, 
          band5_RD, 
          band1_RD, 
          type = "text", 
          digits = 1, 
          df = FALSE)
```

バンド幅が10や5の場合は`university` の係数推定値は500に近いが、バンド幅を1にまで狭めると、推定値はかなり大きくなってしまっている。
また、標準誤差もバンド幅を狭めるごとに大きくなる。

一般的に、RD推定は、閾値前後のサンプルサイズが十分に大きくないと推定結果は不安定になりがちである。一方で、サンプルサイズを確保するために閾値を大きくするとバイアスが生じる可能性が高くなり、閾値を大きくすることによるバイアスを高次多項式によってコントロールしようとすると多項式により推定結果は不安定になる。

ためしに以下では、サンプルサイズを100倍すなわちn=1000,000にして局所線形RDを推定してみる。


```{r}
# データ生成
set.seed(0)
n <- 1000000

ability <- runif(n, min = 0, max = 100)

df <- tibble(ID = 1:n, ability)

df <- df %>% mutate(score = 30*log10(ability) + 
                            rnorm(n, mean = 115, sd = 10))

df <- df %>% mutate(university = case_when(score >= 180 ~ 1, 
                                           TRUE ~ 0))

df <- df %>% mutate(income = 200 + 10*ability + 500*university + 
                              rnorm(n, sd = 50))

#割当変数score_gapの作成
df <- df %>% mutate(score_gap = score - 180)

# バンド幅=50
band30_df <- df %>% filter(-30 <= score_gap & score_gap < 30) 
band30_RD <- lm(income ~ university + score_gap + score_gap:university, 
                data = band30_df) 

# バンド幅=10
band10_df <- df %>% filter(-10 <= score_gap & score_gap < 10) 
band10_RD <- lm(income ~ university + score_gap + score_gap:university, 
                data = band10_df) 

# バンド幅=5
band5_df <- df %>% filter(-5 <= score_gap & score_gap < 5) 
band5_RD <- lm(income ~ university + score_gap + score_gap:university, 
               data = band5_df) 

# バンド幅=1
band1_df <- df %>% filter(-1 <= score_gap & score_gap < 1) 
band1_RD <- lm(income ~ university + score_gap + score_gap:university, 
               data = band1_df) 

stargazer(band30_RD, 
          band10_RD, 
          band5_RD, 
          band1_RD, 
          type = "text",  
          digits = 1, 
          df = FALSE)
```

バンド幅50だと少し下方バイアスがあるように見えるが、バンド幅を10以下にすると、ほぼ500になる。


## 局所多項式RD

サンプルを閾値近傍のものに限定した局所的な分析と多項式（高次元）回帰モデルを組み合わせることもできる。ただし、局所回帰と高次元回帰モデルを組み合わせると標準誤差が大きく傾向があるので、ここでは二次多項式回帰のみを用いてみる。

```{r}
# データ生成
set.seed(0)
n <- 10000

ability <- runif(n, min = 0, max = 100)

df <- tibble(ID = 1:n, ability)

df <- df %>% mutate(score = 30*log10(ability) + 
                            rnorm(n, mean = 115, sd = 10))

df <- df %>% mutate(university = case_when(score >= 180 ~ 1, 
                                           TRUE ~ 0))

df <- df %>% mutate(income = 200 + 10*ability + 500*university + 
                             rnorm(n, sd = 50))

#割当変数score_gapの作成
df <- df %>% mutate(score_gap = score - 180)

# バンド幅=50
band30_df <- df %>% filter(-30 <= score_gap & score_gap < 30) 
band30_RD <- lm(income ~  university + score_gap + I(score_gap^2) +  
              score_gap:university + I(score_gap^2):university, 
              data = band30_df) 

# バンド幅=10
band10_df <- df %>% filter(-10 <= score_gap & score_gap < 10) 
band10_RD <- lm(income ~  university + score_gap + I(score_gap^2) +  
              score_gap:university + I(score_gap^2):university,
              data = band10_df)

# バンド幅=5
band5_df <- df %>% filter(-5 <= score_gap & score_gap < 5) 
band5_RD <- lm(income ~  university + score_gap + I(score_gap^2) +  
              score_gap:university + I(score_gap^2):university, 
              data = band5_df)

# バンド幅=1
band1_df <- df %>% filter(-1 <= score_gap & score_gap < 1) 
band1_RD <- lm(income ~  university + score_gap + I(score_gap^2) +  
              score_gap:university + I(score_gap^2):university, 
              data = band1_df)

stargazer(band30_RD, 
          band10_RD, 
          band5_RD, 
          band1_RD, 
          type = "text", 
          digits = 1, 
          df = FALSE)
```

全体としてRD推定値(`university`の係数推定値）は500よりも大きくなり、とりわけもっともバンド幅が小さいときには500から大きく離れている。

ここでも、サンプルサイズを100倍(100万人)にするとどうなるか見てみよう。

```{r}
# データ生成
set.seed(0)

n <- 1000000

ability <- runif(n, min = 0, max = 100)

df <- tibble(ID = 1:n, ability)

df <- df %>% mutate(score = 30*log10(ability) + 
                            rnorm(n, mean = 115, sd = 10))

df <- df %>% mutate(university = case_when(score >= 180 ~ 1, 
                                           TRUE ~ 0))

df <- df %>% mutate(income = 200 + 10*ability + 500*university + 
                             rnorm(n, sd = 50))

#割当変数score_gapの作成
df <- df %>% mutate(score_gap = score - 180)

# バンド幅=50
band30_df <- df %>% filter(-30 <= score_gap & score_gap < 30) 
band30_RD <- lm(income ~  university + score_gap + I(score_gap^2) +  
              score_gap:university + I(score_gap^2):university, 
              data = band30_df) 

# バンド幅=10
band10_df <- df %>% filter(-10 <= score_gap & score_gap < 10) 
band10_RD <- lm(income ~  university + score_gap + I(score_gap^2) +  
              score_gap:university + I(score_gap^2):university, 
              data = band10_df)

# バンド幅=5
band5_df <- df %>% filter(-5 <= score_gap & score_gap < 5) 
band5_RD <- lm(income ~  university + score_gap + I(score_gap^2) +  
              score_gap:university + I(score_gap^2):university, 
              data = band5_df)

# バンド幅=1
band1_df <- df %>% filter(-1 <= score_gap & score_gap < 1) 
band1_RD <- lm(income ~  university + score_gap + I(score_gap^2) +  
              score_gap:university + I(score_gap^2):university, 
              data = band1_df)

stargazer(band30_RD, 
          band10_RD, 
          band5_RD, 
          band1_RD, 
          type = "text",  
          digits = 1, 
          df = FALSE)
```

どの推定値も500にかなり近くなる。

# 補足

上記の一連の分析からもわかるように、RD推定値は、設定としてRDデザインの適用がふさわしい場合においても、サンプルサイズ、バンド幅、多項式回帰モデルの設定などによって結果が大きくかわりうる。

RD推定の最適な方法については様々な専門的議論がなされ、Rのパッケージも提供されている（{rdrobust}パッケージなど）。

ただし上記の方法で、`lm`関数を使って基本的なRD推定を行うことが可能であるし、この作業によって、何をどう分析しているのかを理解することは重要である。

また標準誤差についても、ここでは修正しなかったが、ロバスト標準誤差に置き換えるほうが望ましい。

# 参考文献

- 安藤道人（2015) 「[多重回帰分析と回帰不連続デザイン](https://www.jil.go.jp/institute/zassi/backnumber/2015/04/pdf/012-013.pdf)」 『日本労働研究雑誌』 No.657 pp.12-13

- 安藤道人「計量経済学２」あるいは「計量経済特論２」の「回帰不連続デザイン」の[講義資料](https://sites.google.com/site/michihito7ando/lectures)

-  [計量経済学応用 回帰不連続デザイン](https://yukiyanai.github.io/jp/classes/econometrics2/contents/R/regression-discontinuity.html) (矢内勇生氏の講義ノート)

- [Chapter 20 - Regression Discontinuity](https://theeffectbook.net/ch-RegressionDiscontinuity.html) (Nick Huntington-Klein (2021)"The Effect: An Introuction to Research Design and Causality")

- [RD Packages](https://rdpackages.github.io/) (より学術的に洗練された方法で不連続回帰を実施するためのRパッケージ)
